<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Spark-flint : Small utility library for apache spark">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Spark-flint</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/sans-sense/spark-flint">View on GitHub</a>

          <h1 id="project_title">Spark-flint</h1>
          <h2 id="project_tagline">Small utility library for apache spark</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/sans-sense/spark-flint/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/sans-sense/spark-flint/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a name="spark-flint" class="anchor" href="#spark-flint"><span class="octicon octicon-link"></span></a>spark-flint</h1>

<p>Adds a simple editor to webUI for spark at http://localhost:4040/plugins. A hack for developers to get a better feel of data exploration. Is not for production, just local data exploration.</p>

<h4>
<a name="starting-it" class="anchor" href="#starting-it"><span class="octicon octicon-link"></span></a>Starting it</h4>

<ul>
<li>:load flint.init<br>
Assuming that we launched spark-shell from this folder or use the relative path, use this command on the spark repl<br>
</li>
</ul><h4>
<a name="sample" class="anchor" href="#sample"><span class="octicon octicon-link"></span></a>Sample</h4>

<p>For code-analysis load the code-analysis component using</p>

<p>:load components/code-analysis/codeAnalysis.init</p>

<p>Analyze the git log for finding top committers, code churn (most changed files), distribution of commit and churn. The commands to run for this.  </p>

<ul>
<li>Generate thg git log for some project with, git log --numstat &gt; detailed.commit.log<br>
</li>
<li>Register the file as a Table in spark with, registerCommitsAsTable("./detailed.commit.log", "commits")<br>
</li>
<li>Query this table from the ui (http://localhost:4040/plugins) with,select author, count(*) as commitCount from commits group by author order by commitCount desc limit 10") or use the alias top10 as top10 commits,author<br>
</li>
<li>On UI view distribution and top values with "analyze commits,author"<br>
</li>
</ul><p>In short the commit log is now mapped as an table (SchemaRDD) which can be queried like any other table. The UI supports other commands like analyze tablename, fieldname.  For a complete list run help. You can of course create any other table in repl and run sql on it from the web UI.</p>

<h3>
<a name="misc" class="anchor" href="#misc"><span class="octicon octicon-link"></span></a>Misc</h3>

<p>If we add <a href="http://repo1.maven.org/maven2/org/ow2/asm/asm-all/5.0.3/asm-all-5.0.3.jar">asm-all-5.0.3.jar</a> to classpath using add_jars, we can also view the source of spark classes from repl.</p>

<ul>
<li>:load components/shell-enhancements/shellEnhance.init</li>
<li>SourceUtil.indexFolder("../../spark")</li>
<li>SourceUtil.source(res6.head._2) where res6 is the output of
sqlContext.sql("select * from commits limit 1").queryExecution.analyzed.output.map {attr =&gt; (attr.name, attr.dataType)}</li>
</ul>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Spark-flint maintained by <a href="https://github.com/sans-sense">sans-sense</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
